# Week 4

## Topics

Measuring what matters: is the metric you are measuring a good proxy for the real-world behavior you want to see?

## Reading

Do you know about the Netflix Prize?  It is a huge deal in the history of recommender systems.  In 2006 Netflix offered a million dollars to anyone who could beat their algorithm by 20%. It took years, but a team did win the prize!  But then the code from the winning team was never used, and the follow up prize for further improvements was canceled. 

Read Netflix description, and how their thinking about the problem of recommending movies to people evolved:
- [Netflix Recommendations: Beyond the 5 stars (Part 1)](https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429)
- [Netflix Recommendations: Beyond the 5 stars (Part 2)](https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-2-d9b96aa399f5)

More resources (not assigned):
- Wikipedia gives a slightly different account than Netflix: https://en.wikipedia.org/wiki/Netflix_Prize 
- The original rules: https://www.netflixprize.com/rules.html
- Play with the data set! https://www.kaggle.com/netflix-inc/netflix-prize-data
- Learn why the $1M algorithm was never used: https://www.wired.com/2012/04/netflix-prize-costs/
- Learn why the follow up was canceled: https://www.wired.com/2010/03/netflix-cancels-contest/

## Tasks

Replication checkpoint 1 due.

## Questions

For the reading response this week write a few sentences about how the failure of the Netflix prize and the failure of replication in our "Are we making much progress?" paper are similar and different.